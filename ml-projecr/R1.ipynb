{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "drMq59Lsl_ay",
    "outputId": "cbdc05c7-a981-420c-ec58-c9c8a917d801",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>market</th>\n",
       "      <th>dur_stay</th>\n",
       "      <th>mode</th>\n",
       "      <th>purpose</th>\n",
       "      <th>area</th>\n",
       "      <th>visits</th>\n",
       "      <th>spend</th>\n",
       "      <th>nights</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>TOTAL ENGLAND</td>\n",
       "      <td>4.431616</td>\n",
       "      <td>1.013484</td>\n",
       "      <td>9.530416</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>3.572186</td>\n",
       "      <td>0.969138</td>\n",
       "      <td>6.954456</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>REST OF ENGLAND</td>\n",
       "      <td>0.859430</td>\n",
       "      <td>0.044346</td>\n",
       "      <td>2.575960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>SOUTHERN ENGLAND</td>\n",
       "      <td>0.859430</td>\n",
       "      <td>0.044346</td>\n",
       "      <td>2.575960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>SOUTH EAST</td>\n",
       "      <td>0.859430</td>\n",
       "      <td>0.044346</td>\n",
       "      <td>2.575960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year        quarter   market    dur_stay mode  purpose              area  \\\n",
       "0  2002  January-March  Belgium  1-3 nights  Air  Holiday     TOTAL ENGLAND   \n",
       "1  2002  January-March  Belgium  1-3 nights  Air  Holiday            LONDON   \n",
       "2  2002  January-March  Belgium  1-3 nights  Air  Holiday   REST OF ENGLAND   \n",
       "3  2002  January-March  Belgium  1-3 nights  Air  Holiday  SOUTHERN ENGLAND   \n",
       "4  2002  January-March  Belgium  1-3 nights  Air  Holiday        SOUTH EAST   \n",
       "\n",
       "     visits     spend    nights  sample  \n",
       "0  4.431616  1.013484  9.530416       6  \n",
       "1  3.572186  0.969138  6.954456       5  \n",
       "2  0.859430  0.044346  2.575960       1  \n",
       "3  0.859430  0.044346  2.575960       1  \n",
       "4  0.859430  0.044346  2.575960       1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:\\Users\\Administrator\\Downloads\\ml_project_cse204-main\\ml_project_cse204-main\\Datasets-under-consideration\\London\\UK_international-visits.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549853 entries, 0 to 549852\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   year      549853 non-null  object \n",
      " 1   quarter   549853 non-null  object \n",
      " 2   market    549853 non-null  object \n",
      " 3   dur_stay  549853 non-null  object \n",
      " 4   mode      549853 non-null  object \n",
      " 5   purpose   549853 non-null  object \n",
      " 6   area      549853 non-null  object \n",
      " 7   visits    549853 non-null  float64\n",
      " 8   spend     549853 non-null  float64\n",
      " 9   nights    549853 non-null  float64\n",
      " 10  sample    549853 non-null  int64  \n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 46.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "ADTllyHn0gix",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming you have a dataframe called 'df' and a list of columns to normalize\n",
    "columns_to_normalize = ['visits','spend','nights', 'sample']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vtz6aFbp0ymq",
    "outputId": "f1d4e057-24dc-45ad-e11e-56acf902ddce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>market</th>\n",
       "      <th>dur_stay</th>\n",
       "      <th>mode</th>\n",
       "      <th>purpose</th>\n",
       "      <th>area</th>\n",
       "      <th>visits</th>\n",
       "      <th>spend</th>\n",
       "      <th>nights</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>TOTAL ENGLAND</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.014925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.011940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>REST OF ENGLAND</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>SOUTHERN ENGLAND</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>SOUTH EAST</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year        quarter   market    dur_stay mode  purpose              area  \\\n",
       "0  2002  January-March  Belgium  1-3 nights  Air  Holiday     TOTAL ENGLAND   \n",
       "1  2002  January-March  Belgium  1-3 nights  Air  Holiday            LONDON   \n",
       "2  2002  January-March  Belgium  1-3 nights  Air  Holiday   REST OF ENGLAND   \n",
       "3  2002  January-March  Belgium  1-3 nights  Air  Holiday  SOUTHERN ENGLAND   \n",
       "4  2002  January-March  Belgium  1-3 nights  Air  Holiday        SOUTH EAST   \n",
       "\n",
       "     visits     spend    nights    sample  \n",
       "0  0.019436  0.002407  0.002366  0.014925  \n",
       "1  0.015667  0.002302  0.001726  0.011940  \n",
       "2  0.003769  0.000108  0.000639  0.000000  \n",
       "3  0.003769  0.000108  0.000639  0.000000  \n",
       "4  0.003769  0.000108  0.000639  0.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2IdEXK1HT_X",
    "outputId": "1c11252e-6903-4d6a-ef84-5e2e93dd7478",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Belgium', 'Holiday'): 2\n",
      "('Belgium', 'Business'): 2\n",
      "('Belgium', 'VFR'): 2\n",
      "('Belgium', 'Miscellaneous'): 2\n",
      "('Belgium', 'Study'): 2\n",
      "('Luxembourg', 'Holiday'): 2\n",
      "('Luxembourg', 'Business'): 2\n",
      "('Luxembourg', 'VFR'): 2\n",
      "('Luxembourg', 'Miscellaneous'): 2\n",
      "('Luxembourg', 'Study'): 2\n",
      "('France', 'Holiday'): 5\n",
      "('France', 'Business'): 2\n",
      "('France', 'VFR'): 2\n",
      "('France', 'Miscellaneous'): 2\n",
      "('France', 'Study'): 2\n",
      "('Germany', 'Holiday'): 4\n",
      "('Germany', 'Business'): 4\n",
      "('Germany', 'VFR'): 2\n",
      "('Germany', 'Miscellaneous'): 2\n",
      "('Germany', 'Study'): 2\n",
      "('Italy', 'Holiday'): 4\n",
      "('Italy', 'Business'): 4\n",
      "('Italy', 'VFR'): 2\n",
      "('Italy', 'Miscellaneous'): 2\n",
      "('Italy', 'Study'): 2\n",
      "('Netherlands', 'Holiday'): 2\n",
      "('Netherlands', 'Business'): 2\n",
      "('Netherlands', 'VFR'): 2\n",
      "('Netherlands', 'Miscellaneous'): 2\n",
      "('Netherlands', 'Study'): 2\n",
      "('Denmark', 'Holiday'): 2\n",
      "('Denmark', 'Business'): 2\n",
      "('Denmark', 'VFR'): 2\n",
      "('Denmark', 'Miscellaneous'): 2\n",
      "('Denmark', 'Study'): 2\n",
      "('Greece', 'Holiday'): 2\n",
      "('Greece', 'Business'): 2\n",
      "('Greece', 'VFR'): 2\n",
      "('Greece', 'Miscellaneous'): 2\n",
      "('Greece', 'Study'): 2\n",
      "('Spain', 'Holiday'): 4\n",
      "('Spain', 'Business'): 4\n",
      "('Spain', 'VFR'): 2\n",
      "('Spain', 'Miscellaneous'): 2\n",
      "('Spain', 'Study'): 2\n",
      "('Portugal', 'Holiday'): 2\n",
      "('Portugal', 'Business'): 2\n",
      "('Portugal', 'VFR'): 2\n",
      "('Portugal', 'Miscellaneous'): 2\n",
      "('Portugal', 'Study'): 2\n",
      "('Austria', 'Holiday'): 2\n",
      "('Austria', 'Business'): 2\n",
      "('Austria', 'VFR'): 2\n",
      "('Austria', 'Miscellaneous'): 2\n",
      "('Austria', 'Study'): 2\n",
      "('Sweden', 'Holiday'): 2\n",
      "('Sweden', 'Business'): 2\n",
      "('Sweden', 'VFR'): 2\n",
      "('Sweden', 'Miscellaneous'): 2\n",
      "('Sweden', 'Study'): 2\n",
      "('Finland', 'Holiday'): 2\n",
      "('Finland', 'Business'): 2\n",
      "('Finland', 'VFR'): 2\n",
      "('Finland', 'Miscellaneous'): 2\n",
      "('Finland', 'Study'): 2\n",
      "('Irish Republic', 'Holiday'): 2\n",
      "('Irish Republic', 'Business'): 2\n",
      "('Irish Republic', 'VFR'): 2\n",
      "('Irish Republic', 'Miscellaneous'): 2\n",
      "('Irish Republic', 'Study'): 2\n",
      "('Turkey', 'Holiday'): 2\n",
      "('Turkey', 'Business'): 2\n",
      "('Turkey', 'VFR'): 2\n",
      "('Turkey', 'Miscellaneous'): 2\n",
      "('Turkey', 'Study'): 2\n",
      "('Switzerland', 'Holiday'): 2\n",
      "('Switzerland', 'Business'): 2\n",
      "('Switzerland', 'VFR'): 2\n",
      "('Switzerland', 'Miscellaneous'): 2\n",
      "('Switzerland', 'Study'): 2\n",
      "('Norway', 'Holiday'): 2\n",
      "('Norway', 'Business'): 2\n",
      "('Norway', 'VFR'): 2\n",
      "('Norway', 'Miscellaneous'): 2\n",
      "('Norway', 'Study'): 2\n",
      "('Iceland', 'Holiday'): 2\n",
      "('Iceland', 'Business'): 2\n",
      "('Iceland', 'VFR'): 2\n",
      "('Iceland', 'Miscellaneous'): 2\n",
      "('Iceland', 'Study'): 2\n",
      "('Czech Republic', 'Holiday'): 2\n",
      "('Czech Republic', 'Business'): 2\n",
      "('Czech Republic', 'VFR'): 2\n",
      "('Czech Republic', 'Miscellaneous'): 2\n",
      "('Czech Republic', 'Study'): 2\n",
      "('Poland', 'Holiday'): 2\n",
      "('Poland', 'Business'): 2\n",
      "('Poland', 'VFR'): 2\n",
      "('Poland', 'Miscellaneous'): 2\n",
      "('Poland', 'Study'): 2\n",
      "('Hungary', 'Holiday'): 2\n",
      "('Hungary', 'Business'): 2\n",
      "('Hungary', 'VFR'): 2\n",
      "('Hungary', 'Miscellaneous'): 2\n",
      "('Hungary', 'Study'): 2\n",
      "('Russia', 'Holiday'): 2\n",
      "('Russia', 'Business'): 2\n",
      "('Russia', 'VFR'): 2\n",
      "('Russia', 'Miscellaneous'): 2\n",
      "('Russia', 'Study'): 2\n",
      "('Other Western Europe', 'Holiday'): 2\n",
      "('Other Western Europe', 'Business'): 2\n",
      "('Other Western Europe', 'VFR'): 2\n",
      "('Other Western Europe', 'Miscellaneous'): 2\n",
      "('Other Western Europe', 'Study'): 2\n",
      "('Other Eastern Europe', 'Holiday'): 2\n",
      "('Other Eastern Europe', 'Business'): 2\n",
      "('Other Eastern Europe', 'VFR'): 2\n",
      "('Other Eastern Europe', 'Miscellaneous'): 2\n",
      "('Other Eastern Europe', 'Study'): 2\n",
      "('USA', 'Holiday'): 3\n",
      "('USA', 'Business'): 2\n",
      "('USA', 'VFR'): 2\n",
      "('USA', 'Miscellaneous'): 2\n",
      "('USA', 'Study'): 2\n",
      "('Canada', 'Holiday'): 3\n",
      "('Canada', 'Business'): 2\n",
      "('Canada', 'VFR'): 2\n",
      "('Canada', 'Miscellaneous'): 2\n",
      "('Canada', 'Study'): 2\n",
      "('Mexico', 'Holiday'): 2\n",
      "('Mexico', 'Business'): 2\n",
      "('Mexico', 'VFR'): 2\n",
      "('Mexico', 'Miscellaneous'): 2\n",
      "('Mexico', 'Study'): 2\n",
      "('Brazil', 'Holiday'): 2\n",
      "('Brazil', 'Business'): 2\n",
      "('Brazil', 'VFR'): 2\n",
      "('Brazil', 'Miscellaneous'): 2\n",
      "('Brazil', 'Study'): 2\n",
      "('Argentina', 'Holiday'): 2\n",
      "('Argentina', 'Business'): 2\n",
      "('Argentina', 'VFR'): 2\n",
      "('Argentina', 'Miscellaneous'): 2\n",
      "('Argentina', 'Study'): 2\n",
      "('Other Central & South America', 'Holiday'): 2\n",
      "('Other Central & South America', 'Business'): 2\n",
      "('Other Central & South America', 'VFR'): 2\n",
      "('Other Central & South America', 'Miscellaneous'): 2\n",
      "('Other Central & South America', 'Study'): 2\n",
      "('Hong Kong', 'Holiday'): 2\n",
      "('Hong Kong', 'Business'): 2\n",
      "('Hong Kong', 'VFR'): 2\n",
      "('Hong Kong', 'Miscellaneous'): 2\n",
      "('Hong Kong', 'Study'): 2\n",
      "('Malaysia', 'Holiday'): 2\n",
      "('Malaysia', 'Business'): 2\n",
      "('Malaysia', 'VFR'): 2\n",
      "('Malaysia', 'Miscellaneous'): 2\n",
      "('Malaysia', 'Study'): 2\n",
      "('Thailand', 'Holiday'): 2\n",
      "('Thailand', 'Business'): 2\n",
      "('Thailand', 'VFR'): 2\n",
      "('Thailand', 'Miscellaneous'): 2\n",
      "('Thailand', 'Study'): 2\n",
      "('Singapore', 'Holiday'): 2\n",
      "('Singapore', 'Business'): 2\n",
      "('Singapore', 'VFR'): 2\n",
      "('Singapore', 'Miscellaneous'): 2\n",
      "('Singapore', 'Study'): 2\n",
      "('Taiwan', 'Holiday'): 2\n",
      "('Taiwan', 'Business'): 2\n",
      "('Taiwan', 'VFR'): 2\n",
      "('Taiwan', 'Miscellaneous'): 2\n",
      "('Taiwan', 'Study'): 2\n",
      "('China', 'Holiday'): 2\n",
      "('China', 'Business'): 2\n",
      "('China', 'VFR'): 2\n",
      "('China', 'Miscellaneous'): 2\n",
      "('China', 'Study'): 2\n",
      "('Other Asia', 'Holiday'): 2\n",
      "('Other Asia', 'Business'): 2\n",
      "('Other Asia', 'VFR'): 2\n",
      "('Other Asia', 'Miscellaneous'): 2\n",
      "('Other Asia', 'Study'): 2\n",
      "('Japan', 'Holiday'): 2\n",
      "('Japan', 'Business'): 2\n",
      "('Japan', 'VFR'): 2\n",
      "('Japan', 'Miscellaneous'): 2\n",
      "('Japan', 'Study'): 2\n",
      "('South Korea', 'Holiday'): 2\n",
      "('South Korea', 'Business'): 2\n",
      "('South Korea', 'VFR'): 2\n",
      "('South Korea', 'Miscellaneous'): 2\n",
      "('South Korea', 'Study'): 2\n",
      "('Australia', 'Holiday'): 2\n",
      "('Australia', 'Business'): 2\n",
      "('Australia', 'VFR'): 2\n",
      "('Australia', 'Miscellaneous'): 2\n",
      "('Australia', 'Study'): 2\n",
      "('New Zealand', 'Holiday'): 2\n",
      "('New Zealand', 'Business'): 2\n",
      "('New Zealand', 'VFR'): 2\n",
      "('New Zealand', 'Miscellaneous'): 2\n",
      "('New Zealand', 'Study'): 2\n",
      "('United Arab Emirates', 'Holiday'): 2\n",
      "('United Arab Emirates', 'Business'): 2\n",
      "('United Arab Emirates', 'VFR'): 2\n",
      "('United Arab Emirates', 'Miscellaneous'): 2\n",
      "('United Arab Emirates', 'Study'): 2\n",
      "('Saudi Arabia', 'Holiday'): 2\n",
      "('Saudi Arabia', 'Business'): 2\n",
      "('Saudi Arabia', 'VFR'): 2\n",
      "('Saudi Arabia', 'Miscellaneous'): 2\n",
      "('Saudi Arabia', 'Study'): 2\n",
      "('Kuwait', 'Holiday'): 2\n",
      "('Kuwait', 'Business'): 2\n",
      "('Kuwait', 'VFR'): 2\n",
      "('Kuwait', 'Miscellaneous'): 2\n",
      "('Kuwait', 'Study'): 2\n",
      "('Other Middle East', 'Holiday'): 2\n",
      "('Other Middle East', 'Business'): 2\n",
      "('Other Middle East', 'VFR'): 2\n",
      "('Other Middle East', 'Miscellaneous'): 2\n",
      "('Other Middle East', 'Study'): 2\n",
      "('Egypt', 'Holiday'): 2\n",
      "('Egypt', 'Business'): 2\n",
      "('Egypt', 'VFR'): 2\n",
      "('Egypt', 'Miscellaneous'): 2\n",
      "('Egypt', 'Study'): 2\n",
      "('Israel', 'Holiday'): 2\n",
      "('Israel', 'Business'): 2\n",
      "('Israel', 'VFR'): 2\n",
      "('Israel', 'Miscellaneous'): 2\n",
      "('Israel', 'Study'): 2\n",
      "('India', 'Holiday'): 2\n",
      "('India', 'Business'): 2\n",
      "('India', 'VFR'): 2\n",
      "('India', 'Miscellaneous'): 2\n",
      "('India', 'Study'): 2\n",
      "('Pakistan', 'Holiday'): 2\n",
      "('Pakistan', 'Business'): 2\n",
      "('Pakistan', 'VFR'): 2\n",
      "('Pakistan', 'Miscellaneous'): 2\n",
      "('Pakistan', 'Study'): 2\n",
      "('South Africa', 'Holiday'): 2\n",
      "('South Africa', 'Business'): 2\n",
      "('South Africa', 'VFR'): 2\n",
      "('South Africa', 'Miscellaneous'): 2\n",
      "('South Africa', 'Study'): 2\n",
      "('Other Southern Africa', 'Holiday'): 2\n",
      "('Other Southern Africa', 'Business'): 2\n",
      "('Other Southern Africa', 'VFR'): 2\n",
      "('Other Southern Africa', 'Miscellaneous'): 2\n",
      "('Other Southern Africa', 'Study'): 2\n",
      "('Nigeria', 'Holiday'): 2\n",
      "('Nigeria', 'Business'): 2\n",
      "('Nigeria', 'VFR'): 2\n",
      "('Nigeria', 'Miscellaneous'): 2\n",
      "('Nigeria', 'Study'): 2\n",
      "('Kenya', 'Holiday'): 2\n",
      "('Kenya', 'Business'): 2\n",
      "('Kenya', 'VFR'): 2\n",
      "('Kenya', 'Miscellaneous'): 2\n",
      "('Kenya', 'Study'): 2\n",
      "('Other Africa', 'Holiday'): 2\n",
      "('Other Africa', 'Business'): 2\n",
      "('Other Africa', 'VFR'): 2\n",
      "('Other Africa', 'Miscellaneous'): 2\n",
      "('Other Africa', 'Study'): 2\n",
      "('Bulgaria', 'Holiday'): 2\n",
      "('Bulgaria', 'Business'): 2\n",
      "('Bulgaria', 'VFR'): 2\n",
      "('Bulgaria', 'Miscellaneous'): 2\n",
      "('Bulgaria', 'Study'): 2\n",
      "('Romania', 'Holiday'): 2\n",
      "('Romania', 'Business'): 2\n",
      "('Romania', 'VFR'): 2\n",
      "('Romania', 'Miscellaneous'): 2\n",
      "('Romania', 'Study'): 2\n",
      "('Serbia', 'Holiday'): 2\n",
      "('Serbia', 'Business'): 2\n",
      "('Serbia', 'VFR'): 2\n",
      "('Serbia', 'Miscellaneous'): 2\n",
      "('Serbia', 'Study'): 2\n",
      "('Chile', 'Holiday'): 2\n",
      "('Chile', 'Business'): 2\n",
      "('Chile', 'VFR'): 2\n",
      "('Chile', 'Miscellaneous'): 2\n",
      "('Chile', 'Study'): 2\n",
      "('Indonesia', 'Holiday'): 2\n",
      "('Indonesia', 'Business'): 2\n",
      "('Indonesia', 'VFR'): 2\n",
      "('Indonesia', 'Miscellaneous'): 2\n",
      "('Indonesia', 'Study'): 2\n",
      "('Bahrain', 'Holiday'): 2\n",
      "('Bahrain', 'Business'): 2\n",
      "('Bahrain', 'VFR'): 2\n",
      "('Bahrain', 'Miscellaneous'): 2\n",
      "('Bahrain', 'Study'): 2\n",
      "('Oman', 'Holiday'): 2\n",
      "('Oman', 'Business'): 2\n",
      "('Oman', 'VFR'): 2\n",
      "('Oman', 'Miscellaneous'): 2\n",
      "('Oman', 'Study'): 2\n",
      "('Qatar', 'Holiday'): 2\n",
      "('Qatar', 'Business'): 2\n",
      "('Qatar', 'VFR'): 2\n",
      "('Qatar', 'Miscellaneous'): 2\n",
      "('Qatar', 'Study'): 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "cultural_engagement_scores = {}\n",
    "\n",
    "# Get unique values from the 'market' and 'purpose' columns\n",
    "markets = df['market'].unique()\n",
    "purposes = df['purpose'].unique()\n",
    "\n",
    "# Assign scores based on market and purpose combinations\n",
    "for market in markets:\n",
    "    for purpose in purposes:\n",
    "        if market == 'France' and purpose == 'Holiday':\n",
    "            score = 5\n",
    "        elif market in ['Germany', 'Italy', 'Spain'] and purpose in ['Holiday', 'Business']:\n",
    "            score = 4\n",
    "        elif market in ['USA', 'Canada'] and purpose == 'Holiday':\n",
    "            score = 3\n",
    "        else:\n",
    "            score = 2\n",
    "\n",
    "        cultural_engagement_scores[(market, purpose)] = score\n",
    "\n",
    "# Print the cultural engagement scores mapping\n",
    "for key, value in cultural_engagement_scores.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "W2mM8QRhG-5C",
    "outputId": "19f73787-7ba2-4fda-d464-23c063d0eebe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>market</th>\n",
       "      <th>dur_stay</th>\n",
       "      <th>mode</th>\n",
       "      <th>purpose</th>\n",
       "      <th>area</th>\n",
       "      <th>visits</th>\n",
       "      <th>spend</th>\n",
       "      <th>nights</th>\n",
       "      <th>sample</th>\n",
       "      <th>cultural_engagement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>TOTAL ENGLAND</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>REST OF ENGLAND</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>SOUTHERN ENGLAND</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>January-March</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1-3 nights</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>SOUTH EAST</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year        quarter   market    dur_stay mode  purpose              area  \\\n",
       "0  2002  January-March  Belgium  1-3 nights  Air  Holiday     TOTAL ENGLAND   \n",
       "1  2002  January-March  Belgium  1-3 nights  Air  Holiday            LONDON   \n",
       "2  2002  January-March  Belgium  1-3 nights  Air  Holiday   REST OF ENGLAND   \n",
       "3  2002  January-March  Belgium  1-3 nights  Air  Holiday  SOUTHERN ENGLAND   \n",
       "4  2002  January-March  Belgium  1-3 nights  Air  Holiday        SOUTH EAST   \n",
       "\n",
       "     visits     spend    nights    sample  cultural_engagement  \n",
       "0  0.019436  0.002407  0.002366  0.014925                    2  \n",
       "1  0.015667  0.002302  0.001726  0.011940                    2  \n",
       "2  0.003769  0.000108  0.000639  0.000000                    2  \n",
       "3  0.003769  0.000108  0.000639  0.000000                    2  \n",
       "4  0.003769  0.000108  0.000639  0.000000                    2  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a new column 'cultural_engagement' based on the mapping\n",
    "df['cultural_engagement'] = df.apply(lambda row: cultural_engagement_scores.get((row['market'], row['purpose'])), axis=1)\n",
    "\n",
    "# Print the updated dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '2002' does not match format '%Y-P' (match)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001B[0m in \u001B[0;36m_to_datetime_with_format\u001B[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001B[0m\n\u001B[0;32m    508\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 509\u001B[1;33m             \u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtz\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconversion\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdatetime_to_datetime64\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    510\u001B[0m             \u001B[0mdta\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDatetimeArray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtz_to_dtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtz\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx\u001B[0m in \u001B[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Unrecognized value type: <class 'int'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_19504/3950694768.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Convert 'year' and 'quarter' to numerical data types\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'year'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_datetime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'year'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'%Y-P'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001B[0m in \u001B[0;36mto_datetime\u001B[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001B[0m\n\u001B[0;32m    881\u001B[0m                 \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtz_localize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtz\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    882\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mABCSeries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 883\u001B[1;33m         \u001B[0mcache_array\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_maybe_cache\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcache\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconvert_listlike\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    884\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mcache_array\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    885\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcache_array\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001B[0m in \u001B[0;36m_maybe_cache\u001B[1;34m(arg, format, cache, convert_listlike)\u001B[0m\n\u001B[0;32m    193\u001B[0m         \u001B[0munique_dates\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    194\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munique_dates\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 195\u001B[1;33m             \u001B[0mcache_dates\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconvert_listlike\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munique_dates\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    196\u001B[0m             \u001B[0mcache_array\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSeries\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcache_dates\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0munique_dates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    197\u001B[0m             \u001B[1;31m# GH#39882 and GH#35888 in case of None and NaT we get duplicates\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001B[0m in \u001B[0;36m_convert_listlike_datetimes\u001B[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001B[0m\n\u001B[0;32m    391\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    392\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mformat\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 393\u001B[1;33m         res = _to_datetime_with_format(\n\u001B[0m\u001B[0;32m    394\u001B[0m             \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morig_arg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtz\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexact\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfer_datetime_format\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m         )\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001B[0m in \u001B[0;36m_to_datetime_with_format\u001B[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001B[0m\n\u001B[0;32m    511\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mDatetimeIndex\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_simple_new\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdta\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    512\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mValueError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 513\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    514\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001B[0m in \u001B[0;36m_to_datetime_with_format\u001B[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001B[0m\n\u001B[0;32m    498\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    499\u001B[0m         \u001B[1;31m# fallback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 500\u001B[1;33m         res = _array_strptime_with_fallback(\n\u001B[0m\u001B[0;32m    501\u001B[0m             \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtz\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfmt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexact\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfer_datetime_format\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    502\u001B[0m         )\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001B[0m in \u001B[0;36m_array_strptime_with_fallback\u001B[1;34m(arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001B[0m\n\u001B[0;32m    434\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    435\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 436\u001B[1;33m         \u001B[0mresult\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimezones\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marray_strptime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfmt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexact\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mexact\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    437\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;34m\"%Z\"\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfmt\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;34m\"%z\"\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfmt\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    438\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0m_return_parsed_timezone_results\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimezones\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtz\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx\u001B[0m in \u001B[0;36mpandas._libs.tslibs.strptime.array_strptime\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: time data '2002' does not match format '%Y-P' (match)"
     ]
    }
   ],
   "source": [
    "# Convert 'year' and 'quarter' to numerical data types\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y-P')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0          2002\n",
       "1          2002\n",
       "2          2002\n",
       "3          2002\n",
       "4          2002\n",
       "          ...  \n",
       "549848    2019P\n",
       "549849    2019P\n",
       "549850    2019P\n",
       "549851    2019P\n",
       "549852    2019P\n",
       "Name: year, Length: 549853, dtype: object>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.year.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "zCPtM8LaKo-Y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visits - Average MAE: 7.26090306088142e-07\n",
      "Visits - Average RSS: 4.889423058989755e-05\n",
      "Spend - Average MAE: 3.0412235317229985e-07\n",
      "Spend - Average RSS: 1.1538361427221307e-05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set the chunk size for streaming/batch processing\n",
    "chunk_size = 10000\n",
    "\n",
    "# Initialize the linear regression models\n",
    "model_visits = LinearRegression()\n",
    "model_spend = LinearRegression()\n",
    "\n",
    "# Initialize variables for accumulating metrics\n",
    "mae_visits_total = 0.0\n",
    "rss_visits_total = 0.0\n",
    "mae_spend_total = 0.0\n",
    "rss_spend_total = 0.0\n",
    "num_samples = 0\n",
    "\n",
    "# Select the features and target variables\n",
    "target_visits = 'visits'\n",
    "target_spend = 'spend'\n",
    "\n",
    "# Separate categorical and numerical features\n",
    "categorical_features = ['dur_stay','market', 'mode', 'purpose', 'area']\n",
    "numerical_features = ['nights', 'sample']\n",
    "\n",
    "# Split the DataFrame into chunks\n",
    "chunks = [df[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "# Iterate over the dataset in chunks\n",
    "for chunk in chunks:\n",
    "    # Preprocess categorical features\n",
    "    chunk_categorical = pd.get_dummies(chunk[categorical_features], columns=categorical_features)\n",
    "\n",
    "    # Preprocess numerical features\n",
    "    chunk_numerical = chunk[numerical_features].copy()\n",
    "    scaler = StandardScaler()\n",
    "    chunk_numerical[numerical_features] = scaler.fit_transform(chunk_numerical)\n",
    "\n",
    "    # Concatenate preprocessed categorical and numerical features\n",
    "    chunk_preprocessed = pd.concat([chunk_categorical, chunk_numerical], axis=1)\n",
    "    \n",
    "    # Add target columns to chunk_preprocessed\n",
    "    chunk_preprocessed[target_visits] = chunk[target_visits]\n",
    "    chunk_preprocessed[target_spend] = chunk[target_spend]\n",
    "    \n",
    "    \n",
    "    # Split the chunk into features and target variables\n",
    "    X = chunk_preprocessed.drop([target_visits, target_spend], axis=1)\n",
    "    y_visits = chunk[target_visits]\n",
    "    y_spend = chunk[target_spend]\n",
    "\n",
    "    # Split the chunk into training and testing sets\n",
    "    X_train, X_test, y_train_visits, y_test_visits = train_test_split(\n",
    "        X, y_visits, test_size=0.2, random_state=42\n",
    "    )\n",
    "    _, _, y_train_spend, y_test_spend = train_test_split(\n",
    "        X, y_spend, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit the linear regression models\n",
    "    model_visits.fit(X_train, y_train_visits)\n",
    "    model_spend.fit(X_train, y_train_spend)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    visits_predictions = model_visits.predict(X_test)\n",
    "    spend_predictions = model_spend.predict(X_test)\n",
    "\n",
    "    # Calculate metrics for this chunk\n",
    "    mae_visits = mean_absolute_error(y_test_visits, visits_predictions)\n",
    "    rss_visits = mean_squared_error(y_test_visits, visits_predictions) * len(y_test_visits)\n",
    "    mae_spend = mean_absolute_error(y_test_spend, spend_predictions)\n",
    "    rss_spend = mean_squared_error(y_test_spend, spend_predictions) * len(y_test_spend)\n",
    "\n",
    "    # Accumulate metrics for the entire dataset\n",
    "    mae_visits_total += mae_visits\n",
    "    rss_visits_total += rss_visits\n",
    "    mae_spend_total += mae_spend\n",
    "    rss_spend_total += rss_spend\n",
    "    num_samples += len(chunk)\n",
    "\n",
    "# Calculate average metrics for the entire dataset\n",
    "avg_mae_visits = mae_visits_total / num_samples\n",
    "avg_rss_visits = rss_visits_total / num_samples\n",
    "avg_mae_spend = mae_spend_total / num_samples\n",
    "avg_rss_spend = rss_spend_total / num_samples\n",
    "\n",
    "print('Visits - Average MAE:', avg_mae_visits)\n",
    "print('Visits - Average RSS:', avg_rss_visits)\n",
    "print('Spend - Average MAE:', avg_mae_spend)\n",
    "print('Spend - Average RSS:', avg_rss_spend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Yil4jvrMCm4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}